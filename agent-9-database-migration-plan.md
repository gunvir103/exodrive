# ExoDrive Database Migration Plan
**Generated by Agent 9 - Database Migration Planner**  
**Date: 2025-08-22**  
**Status: READY FOR REVIEW**  
**Criticality: HIGH - SECURITY VULNERABILITIES BLOCKING DEPLOYMENT**

## Executive Summary

This migration plan addresses critical security vulnerabilities and performance issues identified across the ExoDrive database. The plan is structured in three phases with Phase 1 being **CRITICAL** and must be executed within 48 hours to address security vulnerabilities that are currently blocking all deployments.

### Critical Issues Summary
- **27 functions** missing `SET search_path` (SQL injection vulnerability)
- **3 RLS policies** referencing mutable `user_metadata` (authentication bypass risk)
- Missing indexes causing **N+1 query patterns** and slow performance
- Text-based date fields causing inefficient queries
- Missing price validation allowing potential pricing manipulation

### Migration Phases
1. **Phase 1 (48 hours)**: Critical Security Fixes - 31 migrations
2. **Phase 2 (Week 1)**: Performance Optimizations - 25 migrations  
3. **Phase 3 (Week 2)**: Feature Enhancements - 8 migrations

---

## PHASE 1: CRITICAL SECURITY MIGRATIONS (48 HOURS)

### Issue EXO-128: Fix Function Search Path Vulnerabilities

**Risk Level**: CRITICAL  
**Impact**: SQL Injection vulnerability in 27 functions  
**Execution Time**: ~5 minutes total  

#### Migration 1.1: Fix Trigger Functions Search Path
```sql
-- Migration: 20250623_fix_trigger_functions_search_path
-- Description: Fix search_path for all trigger functions to prevent SQL injection
-- Execution Time: < 1 minute
-- Risk: LOW - Only affects function definitions, not data

BEGIN;

-- Fix handle_new_user function
CREATE OR REPLACE FUNCTION public.handle_new_user()
RETURNS trigger
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = ''
AS $$
BEGIN
  INSERT INTO public.profiles (id, email, role)
  VALUES (NEW.id, NEW.email, 
    CASE 
      WHEN NEW.email IN ('admin@exodrive.com', 'owner@exodrive.com') THEN 'admin'
      ELSE 'user'
    END
  );
  RETURN NEW;
END;
$$;

-- Fix set_updated_at function
CREATE OR REPLACE FUNCTION public.set_updated_at()
RETURNS trigger
LANGUAGE plpgsql
SET search_path = ''
AS $$
BEGIN
  NEW.updated_at = CURRENT_TIMESTAMP;
  RETURN NEW;
END;
$$;

-- Fix update_modified_column function
CREATE OR REPLACE FUNCTION public.update_modified_column()
RETURNS trigger
LANGUAGE plpgsql
SET search_path = ''
AS $$
BEGIN
  NEW.modified = now();
  RETURN NEW;
END;
$$;

-- Fix update_timestamp function
CREATE OR REPLACE FUNCTION public.update_timestamp()
RETURNS trigger
LANGUAGE plpgsql
SET search_path = ''
AS $$
BEGIN
  NEW.updated_at = now();
  RETURN NEW;
END;
$$;

-- Fix update_updated_at_column function
CREATE OR REPLACE FUNCTION public.update_updated_at_column()
RETURNS trigger
LANGUAGE plpgsql
SET search_path = ''
AS $$
BEGIN
  NEW.updated_at = now();
  RETURN NEW;
END;
$$;

-- Fix log_booking_change function
CREATE OR REPLACE FUNCTION public.log_booking_change()
RETURNS trigger
LANGUAGE plpgsql
SET search_path = ''
AS $$
BEGIN
  IF TG_OP = 'UPDATE' THEN
    IF OLD.overall_status IS DISTINCT FROM NEW.overall_status OR
       OLD.payment_status IS DISTINCT FROM NEW.payment_status OR
       OLD.contract_status IS DISTINCT FROM NEW.contract_status THEN
      
      INSERT INTO public.booking_events (
        booking_id,
        event_type,
        actor_type,
        actor_id,
        event_details,
        created_at
      ) VALUES (
        NEW.id,
        'status_change'::public.booking_event_type_enum,
        'system'::public.actor_type_enum,
        'trigger',
        jsonb_build_object(
          'old_overall_status', OLD.overall_status,
          'new_overall_status', NEW.overall_status,
          'old_payment_status', OLD.payment_status,
          'new_payment_status', NEW.payment_status,
          'old_contract_status', OLD.contract_status,
          'new_contract_status', NEW.contract_status
        ),
        NOW()
      );
    END IF;
  END IF;
  RETURN NEW;
END;
$$;

-- Fix log_payment_event function
CREATE OR REPLACE FUNCTION public.log_payment_event()
RETURNS trigger
LANGUAGE plpgsql
SET search_path = ''
AS $$
BEGIN
  IF TG_OP = 'UPDATE' THEN
    IF OLD.status IS DISTINCT FROM NEW.status THEN
      INSERT INTO public.booking_events (
        booking_id,
        event_type,
        actor_type,
        actor_id,
        event_details,
        created_at
      ) VALUES (
        NEW.booking_id,
        'payment_status_change'::public.booking_event_type_enum,
        'system'::public.actor_type_enum,
        'trigger',
        jsonb_build_object(
          'old_status', OLD.status,
          'new_status', NEW.status,
          'payment_id', NEW.id
        ),
        NOW()
      );
    END IF;
  END IF;
  RETURN NEW;
END;
$$;

COMMIT;

-- Rollback Script:
-- Simply re-run the original function definitions without SET search_path
```

#### Migration 1.2: Fix Car Availability Functions
```sql
-- Migration: 20250623_fix_car_availability_functions
-- Description: Fix search_path for car availability management functions
-- Execution Time: < 1 minute
-- Risk: LOW

BEGIN;

-- Fix check_and_reserve_car_availability function
CREATE OR REPLACE FUNCTION public.check_and_reserve_car_availability(
  p_car_id uuid,
  p_start_date date,
  p_end_date date,
  p_booking_id uuid
)
RETURNS boolean
LANGUAGE plpgsql
SET search_path = ''
AS $$
DECLARE
  v_date date;
  v_available boolean := true;
BEGIN
  -- Check availability for each date in range
  FOR v_date IN SELECT generate_series(p_start_date, p_end_date - interval '1 day', '1 day'::interval)::date
  LOOP
    -- Check if date is available
    IF EXISTS (
      SELECT 1 FROM public.car_availability
      WHERE car_id = p_car_id
      AND date = v_date
      AND status != 'available'::public.car_availability_status_enum
    ) THEN
      v_available := false;
      EXIT;
    END IF;
  END LOOP;

  -- If available, reserve the dates
  IF v_available THEN
    FOR v_date IN SELECT generate_series(p_start_date, p_end_date - interval '1 day', '1 day'::interval)::date
    LOOP
      INSERT INTO public.car_availability (car_id, date, status, booking_id)
      VALUES (p_car_id, v_date, 'held'::public.car_availability_status_enum, p_booking_id)
      ON CONFLICT (car_id, date) 
      DO UPDATE SET 
        status = 'held'::public.car_availability_status_enum,
        booking_id = p_booking_id,
        updated_at = NOW();
    END LOOP;
  END IF;

  RETURN v_available;
END;
$$;

-- Fix clear_car_availability_hold function
CREATE OR REPLACE FUNCTION public.clear_car_availability_hold(p_booking_id uuid)
RETURNS void
LANGUAGE plpgsql
SET search_path = ''
AS $$
BEGIN
  UPDATE public.car_availability
  SET status = 'available'::public.car_availability_status_enum,
      booking_id = NULL,
      updated_at = NOW()
  WHERE booking_id = p_booking_id
  AND status = 'held'::public.car_availability_status_enum;
END;
$$;

-- Fix confirm_car_availability_after_confirm function
CREATE OR REPLACE FUNCTION public.confirm_car_availability_after_confirm()
RETURNS trigger
LANGUAGE plpgsql
SET search_path = ''
AS $$
BEGIN
  IF NEW.overall_status = 'confirmed' AND OLD.overall_status != 'confirmed' THEN
    UPDATE public.car_availability
    SET status = 'booked'::public.car_availability_status_enum,
        updated_at = NOW()
    WHERE booking_id = NEW.id
    AND status = 'held'::public.car_availability_status_enum;
  END IF;
  RETURN NEW;
END;
$$;

-- Fix free_car_availability_after_cancel function
CREATE OR REPLACE FUNCTION public.free_car_availability_after_cancel()
RETURNS trigger
LANGUAGE plpgsql
SET search_path = ''
AS $$
BEGIN
  IF NEW.overall_status = 'cancelled' AND OLD.overall_status != 'cancelled' THEN
    UPDATE public.car_availability
    SET status = 'available'::public.car_availability_status_enum,
        booking_id = NULL,
        updated_at = NOW()
    WHERE booking_id = NEW.id;
  END IF;
  RETURN NEW;
END;
$$;

-- Fix duplicate functions
CREATE OR REPLACE FUNCTION public.fn_confirm_car_availability_after_booking_confirmation()
RETURNS trigger
LANGUAGE plpgsql
SET search_path = ''
AS $$
BEGIN
  IF NEW.overall_status = 'confirmed' AND OLD.overall_status != 'confirmed' THEN
    UPDATE public.car_availability
    SET status = 'booked'::public.car_availability_status_enum,
        updated_at = NOW()
    WHERE booking_id = NEW.id
    AND status IN ('held'::public.car_availability_status_enum, 'pending'::public.car_availability_status_enum);
  END IF;
  RETURN NEW;
END;
$$;

CREATE OR REPLACE FUNCTION public.fn_free_car_availability_after_cancel()
RETURNS trigger
LANGUAGE plpgsql
SET search_path = ''
AS $$
BEGIN
  IF NEW.overall_status = 'cancelled' AND OLD.overall_status != 'cancelled' THEN
    UPDATE public.car_availability
    SET status = 'available'::public.car_availability_status_enum,
        booking_id = NULL,
        updated_at = NOW()
    WHERE booking_id = NEW.id;
  END IF;
  RETURN NEW;
END;
$$;

COMMIT;
```

#### Migration 1.3: Fix Admin and Car Management Functions
```sql
-- Migration: 20250623_fix_admin_car_functions
-- Description: Fix search_path for admin and car management functions
-- Execution Time: < 1 minute
-- Risk: LOW

BEGIN;

-- Fix is_admin function
CREATE OR REPLACE FUNCTION public.is_admin(email text)
RETURNS boolean
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = ''
AS $$
BEGIN
  RETURN EXISTS (
    SELECT 1 FROM public.profiles
    WHERE profiles.email = is_admin.email
    AND profiles.role = 'admin'
  );
END;
$$;

-- Fix is_admin_user function
CREATE OR REPLACE FUNCTION public.is_admin_user()
RETURNS boolean
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = ''
AS $$
BEGIN
  RETURN EXISTS (
    SELECT 1 FROM public.profiles
    WHERE id = auth.uid()
    AND role = 'admin'
  );
END;
$$;

-- Fix set_active_hero function
CREATE OR REPLACE FUNCTION public.set_active_hero(hero_id uuid)
RETURNS void
LANGUAGE plpgsql
SET search_path = ''
AS $$
BEGIN
  -- Deactivate all heroes
  UPDATE public.hero_content SET is_active = false;
  
  -- Activate the selected hero
  UPDATE public.hero_content 
  SET is_active = true 
  WHERE id = hero_id;
END;
$$;

-- Fix create_car_atomic function (overloaded version 1)
CREATE OR REPLACE FUNCTION public.create_car_atomic(
  p_name text,
  p_category text,
  p_description text,
  p_short_description text,
  p_available boolean,
  p_featured boolean,
  p_hidden boolean,
  p_pricing jsonb,
  p_images jsonb,
  p_features jsonb,
  p_specifications jsonb
)
RETURNS uuid
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = ''
AS $$
DECLARE
  v_car_id uuid;
  v_image jsonb;
  v_feature jsonb;
  v_spec jsonb;
BEGIN
  -- Insert car
  INSERT INTO public.cars (name, category, description, short_description, available, featured, hidden)
  VALUES (p_name, p_category, p_description, p_short_description, p_available, p_featured, p_hidden)
  RETURNING id INTO v_car_id;

  -- Insert pricing
  INSERT INTO public.car_pricing (car_id, daily_rate, weekly_rate, monthly_rate, security_deposit)
  VALUES (
    v_car_id,
    (p_pricing->>'daily_rate')::numeric,
    (p_pricing->>'weekly_rate')::numeric,
    (p_pricing->>'monthly_rate')::numeric,
    (p_pricing->>'security_deposit')::numeric
  );

  -- Insert images
  FOR v_image IN SELECT * FROM jsonb_array_elements(p_images)
  LOOP
    INSERT INTO public.car_images (car_id, image_url, alt_text, display_order, is_primary)
    VALUES (
      v_car_id,
      v_image->>'image_url',
      v_image->>'alt_text',
      (v_image->>'display_order')::integer,
      (v_image->>'is_primary')::boolean
    );
  END LOOP;

  -- Insert features
  FOR v_feature IN SELECT * FROM jsonb_array_elements(p_features)
  LOOP
    INSERT INTO public.car_features (car_id, name, icon, category)
    VALUES (
      v_car_id,
      v_feature->>'name',
      v_feature->>'icon',
      v_feature->>'category'
    );
  END LOOP;

  -- Insert specifications
  FOR v_spec IN SELECT * FROM jsonb_array_elements(p_specifications)
  LOOP
    INSERT INTO public.car_specifications (car_id, name, value, category)
    VALUES (
      v_car_id,
      v_spec->>'name',
      v_spec->>'value',
      v_spec->>'category'
    );
  END LOOP;

  RETURN v_car_id;
END;
$$;

-- Fix update_car_atomic function
CREATE OR REPLACE FUNCTION public.update_car_atomic(
  p_car_id uuid,
  p_name text,
  p_category text,
  p_description text,
  p_short_description text,
  p_available boolean,
  p_featured boolean,
  p_hidden boolean,
  p_pricing jsonb,
  p_images jsonb,
  p_features jsonb,
  p_specifications jsonb
)
RETURNS void
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = ''
AS $$
DECLARE
  v_image jsonb;
  v_feature jsonb;
  v_spec jsonb;
BEGIN
  -- Update car
  UPDATE public.cars
  SET name = p_name,
      category = p_category,
      description = p_description,
      short_description = p_short_description,
      available = p_available,
      featured = p_featured,
      hidden = p_hidden,
      updated_at = NOW()
  WHERE id = p_car_id;

  -- Update pricing
  UPDATE public.car_pricing
  SET daily_rate = (p_pricing->>'daily_rate')::numeric,
      weekly_rate = (p_pricing->>'weekly_rate')::numeric,
      monthly_rate = (p_pricing->>'monthly_rate')::numeric,
      security_deposit = (p_pricing->>'security_deposit')::numeric,
      updated_at = NOW()
  WHERE car_id = p_car_id;

  -- Delete and re-insert images
  DELETE FROM public.car_images WHERE car_id = p_car_id;
  FOR v_image IN SELECT * FROM jsonb_array_elements(p_images)
  LOOP
    INSERT INTO public.car_images (car_id, image_url, alt_text, display_order, is_primary)
    VALUES (
      p_car_id,
      v_image->>'image_url',
      v_image->>'alt_text',
      (v_image->>'display_order')::integer,
      (v_image->>'is_primary')::boolean
    );
  END LOOP;

  -- Delete and re-insert features
  DELETE FROM public.car_features WHERE car_id = p_car_id;
  FOR v_feature IN SELECT * FROM jsonb_array_elements(p_features)
  LOOP
    INSERT INTO public.car_features (car_id, name, icon, category)
    VALUES (
      p_car_id,
      v_feature->>'name',
      v_feature->>'icon',
      v_feature->>'category'
    );
  END LOOP;

  -- Delete and re-insert specifications
  DELETE FROM public.car_specifications WHERE car_id = p_car_id;
  FOR v_spec IN SELECT * FROM jsonb_array_elements(p_specifications)
  LOOP
    INSERT INTO public.car_specifications (car_id, name, value, category)
    VALUES (
      p_car_id,
      v_spec->>'name',
      v_spec->>'value',
      v_spec->>'category'
    );
  END LOOP;
END;
$$;

-- Fix delete_car_atomic function
CREATE OR REPLACE FUNCTION public.delete_car_atomic(p_car_id uuid)
RETURNS void
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = ''
AS $$
BEGIN
  -- Delete in correct order due to foreign keys
  DELETE FROM public.car_specifications WHERE car_id = p_car_id;
  DELETE FROM public.car_features WHERE car_id = p_car_id;
  DELETE FROM public.car_images WHERE car_id = p_car_id;
  DELETE FROM public.car_pricing WHERE car_id = p_car_id;
  DELETE FROM public.car_availability WHERE car_id = p_car_id;
  DELETE FROM public.car_reviews WHERE car_id = p_car_id;
  DELETE FROM public.car_additional_fees WHERE car_id = p_car_id;
  DELETE FROM public.cars WHERE id = p_car_id;
END;
$$;

COMMIT;
```

#### Migration 1.4: Fix Payment and Pricing Functions
```sql
-- Migration: 20250623_fix_payment_pricing_functions
-- Description: Fix search_path for payment and pricing validation functions
-- Execution Time: < 1 minute
-- Risk: MEDIUM - Critical for payment security

BEGIN;

-- Fix calculate_booking_price function
CREATE OR REPLACE FUNCTION public.calculate_booking_price(
  p_car_id uuid,
  p_start_date timestamp with time zone,
  p_end_date timestamp with time zone
)
RETURNS numeric
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = ''
AS $$
DECLARE
  v_daily_rate numeric;
  v_weekly_rate numeric;
  v_monthly_rate numeric;
  v_days integer;
  v_weeks integer;
  v_months integer;
  v_remaining_days integer;
  v_total_price numeric := 0;
BEGIN
  -- Get car pricing
  SELECT daily_rate, weekly_rate, monthly_rate
  INTO v_daily_rate, v_weekly_rate, v_monthly_rate
  FROM public.car_pricing
  WHERE car_id = p_car_id;

  IF v_daily_rate IS NULL THEN
    RAISE EXCEPTION 'Car pricing not found for car_id: %', p_car_id;
  END IF;

  -- Calculate duration
  v_days := EXTRACT(DAY FROM (p_end_date - p_start_date))::integer;
  
  -- Calculate optimal pricing (months -> weeks -> days)
  v_months := v_days / 30;
  v_remaining_days := v_days % 30;
  v_weeks := v_remaining_days / 7;
  v_remaining_days := v_remaining_days % 7;

  -- Calculate total
  v_total_price := (v_months * COALESCE(v_monthly_rate, v_daily_rate * 30)) +
                   (v_weeks * COALESCE(v_weekly_rate, v_daily_rate * 7)) +
                   (v_remaining_days * v_daily_rate);

  RETURN v_total_price;
END;
$$;

-- Fix validate_booking_price function
CREATE OR REPLACE FUNCTION public.validate_booking_price(
  p_car_id uuid,
  p_start_date timestamp with time zone,
  p_end_date timestamp with time zone,
  p_client_price numeric
)
RETURNS boolean
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = ''
AS $$
DECLARE
  v_calculated_price numeric;
  v_tolerance numeric := 0.01; -- Allow 1 cent tolerance for rounding
BEGIN
  -- Calculate the correct price
  v_calculated_price := public.calculate_booking_price(p_car_id, p_start_date, p_end_date);
  
  -- Check if client price matches calculated price (within tolerance)
  IF ABS(v_calculated_price - p_client_price) <= v_tolerance THEN
    RETURN true;
  ELSE
    -- Log price mismatch for monitoring
    RAISE WARNING 'Price validation failed. Expected: %, Got: %, Difference: %',
      v_calculated_price, p_client_price, ABS(v_calculated_price - p_client_price);
    RETURN false;
  END IF;
END;
$$;

-- Fix determine_payment_capture_time function
CREATE OR REPLACE FUNCTION public.determine_payment_capture_time(p_booking_id uuid)
RETURNS timestamp with time zone
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = ''
AS $$
DECLARE
  v_rule record;
  v_booking record;
  v_capture_time timestamp with time zone;
BEGIN
  -- Get booking details
  SELECT * INTO v_booking
  FROM public.bookings
  WHERE id = p_booking_id;

  -- Find applicable rule
  SELECT * INTO v_rule
  FROM public.payment_capture_rules
  WHERE is_active = true
  ORDER BY priority DESC
  LIMIT 1;

  IF v_rule IS NULL THEN
    -- Default: capture 24 hours before start
    v_capture_time := v_booking.start_date - interval '24 hours';
  ELSE
    -- Apply rule based on trigger_type
    CASE v_rule.trigger_type
      WHEN 'on_confirmation' THEN
        v_capture_time := NOW() + (v_rule.hours_after_trigger * interval '1 hour');
      WHEN 'before_checkin' THEN
        v_capture_time := v_booking.start_date - (v_rule.hours_before_checkin * interval '1 hour');
      WHEN 'days_before_checkin' THEN
        v_capture_time := v_booking.start_date - (v_rule.days_before_checkin * interval '1 day');
      ELSE
        v_capture_time := v_booking.start_date - interval '24 hours';
    END CASE;
  END IF;

  -- Ensure capture time is not in the past
  IF v_capture_time < NOW() THEN
    v_capture_time := NOW() + interval '1 hour';
  END IF;

  RETURN v_capture_time;
END;
$$;

-- Fix mark_payment_captured function
CREATE OR REPLACE FUNCTION public.mark_payment_captured(
  p_booking_id uuid,
  p_capture_id text,
  p_captured_amount numeric
)
RETURNS void
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = ''
AS $$
BEGIN
  UPDATE public.payments
  SET status = 'captured'::public.payment_status_enum,
      capture_id = p_capture_id,
      captured_amount = p_captured_amount,
      captured_at = NOW(),
      updated_at = NOW()
  WHERE booking_id = p_booking_id
  AND status = 'authorized'::public.payment_status_enum;

  -- Update booking payment status
  UPDATE public.bookings
  SET payment_status = 'captured'::public.payment_status_enum,
      updated_at = NOW()
  WHERE id = p_booking_id;
END;
$$;

-- Fix process_scheduled_payment_captures function
CREATE OR REPLACE FUNCTION public.process_scheduled_payment_captures()
RETURNS table(booking_id uuid, scheduled_time timestamp with time zone)
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = ''
AS $$
BEGIN
  RETURN QUERY
  SELECT b.id, b.payment_capture_scheduled_at
  FROM public.bookings b
  JOIN public.payments p ON p.booking_id = b.id
  WHERE b.payment_status = 'authorized'::public.payment_status_enum
  AND b.payment_capture_scheduled_at <= NOW()
  AND p.status = 'authorized'::public.payment_status_enum;
END;
$$;

-- Fix schedule_payment_capture_on_confirmation function
CREATE OR REPLACE FUNCTION public.schedule_payment_capture_on_confirmation()
RETURNS trigger
LANGUAGE plpgsql
SET search_path = ''
AS $$
BEGIN
  IF NEW.overall_status = 'confirmed' AND OLD.overall_status != 'confirmed' THEN
    NEW.payment_capture_scheduled_at := public.determine_payment_capture_time(NEW.id);
  END IF;
  RETURN NEW;
END;
$$;

-- Fix schedule_payment_capture_on_creation function  
CREATE OR REPLACE FUNCTION public.schedule_payment_capture_on_creation()
RETURNS trigger
LANGUAGE plpgsql
SET search_path = ''
AS $$
BEGIN
  IF NEW.payment_status = 'authorized' THEN
    NEW.payment_capture_scheduled_at := public.determine_payment_capture_time(NEW.id);
  END IF;
  RETURN NEW;
END;
$$;

COMMIT;
```

### Migration 1.5: Fix RLS Policies Using user_metadata
```sql
-- Migration: 20250623_fix_rls_user_metadata
-- Description: Replace insecure user_metadata references with app_metadata
-- Execution Time: < 1 minute
-- Risk: HIGH - Changes authentication logic

BEGIN;

-- Fix inbox_emails RLS policy
DROP POLICY IF EXISTS "Admins can manage inbox_emails" ON public.inbox_emails;

CREATE POLICY "Admins can manage inbox_emails" ON public.inbox_emails
FOR ALL
USING (
  EXISTS (
    SELECT 1 FROM public.profiles
    WHERE profiles.id = auth.uid()
    AND profiles.role = 'admin'
  )
);

-- Fix bookings RLS policy
DROP POLICY IF EXISTS "Admins can manage all bookings" ON public.bookings;

CREATE POLICY "Admins can manage all bookings" ON public.bookings
FOR ALL
USING (
  EXISTS (
    SELECT 1 FROM public.profiles
    WHERE profiles.id = auth.uid()
    AND profiles.role = 'admin'
  )
);

-- Fix customers RLS policy
DROP POLICY IF EXISTS "Admins can manage all customers" ON public.customers;

CREATE POLICY "Admins can manage all customers" ON public.customers
FOR ALL
USING (
  EXISTS (
    SELECT 1 FROM public.profiles
    WHERE profiles.id = auth.uid()
    AND profiles.role = 'admin'
  )
);

-- Add migration to properly set admin roles in profiles table
-- This ensures admins are properly identified
UPDATE public.profiles
SET role = 'admin'
WHERE email IN (
  SELECT DISTINCT email 
  FROM auth.users 
  WHERE raw_user_meta_data->>'role' = 'admin'
  OR email IN ('admin@exodrive.com', 'owner@exodrive.com')
);

COMMIT;

-- Rollback Script:
-- Recreate original policies using user_metadata (NOT RECOMMENDED)
```

---

## PHASE 2: PERFORMANCE OPTIMIZATIONS (WEEK 1)

### Migration 2.1: Add Missing Critical Indexes
```sql
-- Migration: 20250624_add_missing_indexes
-- Description: Add indexes for frequently queried columns
-- Execution Time: ~2-5 minutes depending on data volume
-- Risk: LOW - May cause brief locks during creation

BEGIN;

-- Add composite index for booking queries
CREATE INDEX CONCURRENTLY idx_bookings_customer_dates 
ON public.bookings(customer_id, start_date, end_date)
WHERE overall_status != 'cancelled';

-- Add index for date range queries
CREATE INDEX CONCURRENTLY idx_bookings_date_range
ON public.bookings USING gist (
  tstzrange(start_date, end_date, '[)')
);

-- Add indexes for status filtering
CREATE INDEX CONCURRENTLY idx_bookings_overall_status 
ON public.bookings(overall_status)
WHERE overall_status IN ('pending', 'confirmed', 'in_progress');

CREATE INDEX CONCURRENTLY idx_bookings_payment_status
ON public.bookings(payment_status)
WHERE payment_status IN ('pending', 'authorized', 'captured');

-- Add indexes for car availability queries
CREATE INDEX CONCURRENTLY idx_car_availability_date_status
ON public.car_availability(date, status)
WHERE status = 'available';

CREATE INDEX CONCURRENTLY idx_car_availability_car_date_range
ON public.car_availability(car_id, date)
WHERE status != 'available';

-- Add indexes for created_at queries (for admin dashboards)
CREATE INDEX CONCURRENTLY idx_bookings_created_at 
ON public.bookings(created_at DESC);

CREATE INDEX CONCURRENTLY idx_payments_created_at
ON public.payments(created_at DESC);

CREATE INDEX CONCURRENTLY idx_customers_created_at
ON public.customers(created_at DESC);

-- Add index for email lookups
CREATE INDEX CONCURRENTLY idx_customers_email_lower
ON public.customers(lower(email));

-- Add index for car slug lookups
CREATE INDEX CONCURRENTLY idx_cars_available_featured
ON public.cars(available, featured)
WHERE hidden = false;

COMMIT;

-- Rollback Script:
DROP INDEX IF EXISTS idx_bookings_customer_dates;
DROP INDEX IF EXISTS idx_bookings_date_range;
DROP INDEX IF EXISTS idx_bookings_overall_status;
DROP INDEX IF EXISTS idx_bookings_payment_status;
DROP INDEX IF EXISTS idx_car_availability_date_status;
DROP INDEX IF EXISTS idx_car_availability_car_date_range;
DROP INDEX IF EXISTS idx_bookings_created_at;
DROP INDEX IF EXISTS idx_payments_created_at;
DROP INDEX IF EXISTS idx_customers_created_at;
DROP INDEX IF EXISTS idx_customers_email_lower;
DROP INDEX IF EXISTS idx_cars_available_featured;
```

### Migration 2.2: Optimize Date Field Types
```sql
-- Migration: 20250624_optimize_date_fields
-- Description: Convert text date fields to proper date types
-- Execution Time: ~1 minute
-- Risk: MEDIUM - Requires data migration

BEGIN;

-- Create new column with proper type
ALTER TABLE public.car_reviews 
ADD COLUMN review_date date;

-- Migrate data with validation
UPDATE public.car_reviews
SET review_date = 
  CASE 
    WHEN date ~ '^\d{4}-\d{2}-\d{2}$' THEN date::date
    ELSE current_date
  END;

-- Add NOT NULL constraint
ALTER TABLE public.car_reviews
ALTER COLUMN review_date SET NOT NULL;

-- Create index on new column
CREATE INDEX idx_car_reviews_review_date 
ON public.car_reviews(review_date DESC);

-- Drop old column (do this in a separate migration after verification)
-- ALTER TABLE public.car_reviews DROP COLUMN date;

COMMIT;

-- Rollback Script:
ALTER TABLE public.car_reviews DROP COLUMN review_date;
DROP INDEX IF EXISTS idx_car_reviews_review_date;
```

### Migration 2.3: Optimize N+1 Query Pattern for Car Availability
```sql
-- Migration: 20250624_optimize_car_availability_queries
-- Description: Create materialized view for car availability summary
-- Execution Time: ~1 minute
-- Risk: LOW

BEGIN;

-- Create function to get availability summary
CREATE OR REPLACE FUNCTION public.get_car_availability_summary(
  p_start_date date,
  p_end_date date,
  p_car_ids uuid[] DEFAULT NULL
)
RETURNS TABLE (
  car_id uuid,
  available_days integer,
  blocked_days integer,
  total_days integer,
  is_fully_available boolean
)
LANGUAGE plpgsql
STABLE
SET search_path = ''
AS $$
BEGIN
  RETURN QUERY
  WITH date_range AS (
    SELECT generate_series(p_start_date, p_end_date - interval '1 day', '1 day'::interval)::date AS date
  ),
  car_filter AS (
    SELECT id FROM public.cars
    WHERE p_car_ids IS NULL OR id = ANY(p_car_ids)
  ),
  availability_data AS (
    SELECT 
      cf.id as car_id,
      COUNT(*) FILTER (WHERE ca.status = 'available' OR ca.status IS NULL) as available_days,
      COUNT(*) FILTER (WHERE ca.status != 'available' AND ca.status IS NOT NULL) as blocked_days,
      COUNT(*) as total_days
    FROM car_filter cf
    CROSS JOIN date_range dr
    LEFT JOIN public.car_availability ca 
      ON ca.car_id = cf.id 
      AND ca.date = dr.date
    GROUP BY cf.id
  )
  SELECT 
    car_id,
    available_days,
    blocked_days,
    total_days,
    (available_days = total_days) as is_fully_available
  FROM availability_data;
END;
$$;

-- Create index to support this function
CREATE INDEX CONCURRENTLY idx_car_availability_lookup
ON public.car_availability(car_id, date, status);

COMMIT;

-- Rollback Script:
DROP FUNCTION IF EXISTS public.get_car_availability_summary;
DROP INDEX IF EXISTS idx_car_availability_lookup;
```

### Migration 2.4: Add Database Triggers for Denormalization
```sql
-- Migration: 20250624_add_denormalization_triggers
-- Description: Add triggers to maintain denormalized data for performance
-- Execution Time: < 1 minute
-- Risk: LOW

BEGIN;

-- Add booking count to customers table
ALTER TABLE public.customers
ADD COLUMN IF NOT EXISTS booking_count integer DEFAULT 0,
ADD COLUMN IF NOT EXISTS total_spent numeric DEFAULT 0;

-- Create function to update customer stats
CREATE OR REPLACE FUNCTION public.update_customer_stats()
RETURNS trigger
LANGUAGE plpgsql
SET search_path = ''
AS $$
BEGIN
  IF TG_OP = 'INSERT' THEN
    UPDATE public.customers
    SET booking_count = booking_count + 1,
        total_spent = total_spent + NEW.total_price
    WHERE id = NEW.customer_id;
  ELSIF TG_OP = 'UPDATE' THEN
    IF NEW.overall_status = 'cancelled' AND OLD.overall_status != 'cancelled' THEN
      UPDATE public.customers
      SET booking_count = booking_count - 1,
          total_spent = total_spent - NEW.total_price
      WHERE id = NEW.customer_id;
    ELSIF NEW.overall_status != 'cancelled' AND OLD.overall_status = 'cancelled' THEN
      UPDATE public.customers
      SET booking_count = booking_count + 1,
          total_spent = total_spent + NEW.total_price
      WHERE id = NEW.customer_id;
    END IF;
  ELSIF TG_OP = 'DELETE' THEN
    IF OLD.overall_status != 'cancelled' THEN
      UPDATE public.customers
      SET booking_count = booking_count - 1,
          total_spent = total_spent - OLD.total_price
      WHERE id = OLD.customer_id;
    END IF;
  END IF;
  RETURN NULL;
END;
$$;

-- Create trigger
CREATE TRIGGER update_customer_stats_trigger
AFTER INSERT OR UPDATE OR DELETE ON public.bookings
FOR EACH ROW EXECUTE FUNCTION public.update_customer_stats();

-- Backfill existing data
UPDATE public.customers c
SET booking_count = stats.count,
    total_spent = stats.sum
FROM (
  SELECT customer_id, COUNT(*) as count, SUM(total_price) as sum
  FROM public.bookings
  WHERE overall_status != 'cancelled'
  GROUP BY customer_id
) stats
WHERE c.id = stats.customer_id;

COMMIT;

-- Rollback Script:
DROP TRIGGER IF EXISTS update_customer_stats_trigger ON public.bookings;
DROP FUNCTION IF EXISTS public.update_customer_stats();
ALTER TABLE public.customers 
  DROP COLUMN IF EXISTS booking_count,
  DROP COLUMN IF EXISTS total_spent;
```

---

## PHASE 3: FEATURE ENHANCEMENTS (WEEK 2)

### Migration 3.1: Enhanced DocuSeal Integration
```sql
-- Migration: 20250625_enhance_docuseal_integration
-- Description: Add comprehensive DocuSeal contract management
-- Execution Time: < 1 minute
-- Risk: LOW

BEGIN;

-- Add DocuSeal webhook tracking
CREATE TABLE IF NOT EXISTS public.docuseal_webhooks (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  booking_id uuid REFERENCES public.bookings(id) ON DELETE CASCADE,
  event_type text NOT NULL,
  payload jsonb NOT NULL,
  processed_at timestamp with time zone,
  error_message text,
  retry_count integer DEFAULT 0,
  created_at timestamp with time zone DEFAULT NOW()
);

-- Add RLS
ALTER TABLE public.docuseal_webhooks ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Service role can manage webhooks" ON public.docuseal_webhooks
FOR ALL
USING (true)
WITH CHECK (true);

-- Add index for webhook processing
CREATE INDEX idx_docuseal_webhooks_unprocessed
ON public.docuseal_webhooks(created_at)
WHERE processed_at IS NULL;

-- Add function to process DocuSeal webhooks
CREATE OR REPLACE FUNCTION public.process_docuseal_webhook(
  p_booking_id uuid,
  p_event_type text,
  p_payload jsonb
)
RETURNS void
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = ''
AS $$
BEGIN
  -- Insert webhook record
  INSERT INTO public.docuseal_webhooks (
    booking_id, event_type, payload
  ) VALUES (
    p_booking_id, p_event_type, p_payload
  );

  -- Process based on event type
  CASE p_event_type
    WHEN 'submission.completed' THEN
      UPDATE public.bookings
      SET contract_status = 'signed'::public.contract_status_enum,
          contract_signed_at = NOW(),
          contract_submission_id = p_payload->>'submission_id',
          updated_at = NOW()
      WHERE id = p_booking_id;
      
    WHEN 'submission.created' THEN
      UPDATE public.bookings
      SET contract_status = 'sent'::public.contract_status_enum,
          contract_submission_id = p_payload->>'submission_id',
          updated_at = NOW()
      WHERE id = p_booking_id;
  END CASE;
END;
$$;

COMMIT;

-- Rollback Script:
DROP FUNCTION IF EXISTS public.process_docuseal_webhook;
DROP TABLE IF EXISTS public.docuseal_webhooks;
```

### Migration 3.2: Payment Retry Logic
```sql
-- Migration: 20250625_payment_retry_logic
-- Description: Add payment retry mechanism
-- Execution Time: < 1 minute
-- Risk: LOW

BEGIN;

-- Add retry tracking to payments
ALTER TABLE public.payments
ADD COLUMN IF NOT EXISTS retry_count integer DEFAULT 0,
ADD COLUMN IF NOT EXISTS last_retry_at timestamp with time zone,
ADD COLUMN IF NOT EXISTS next_retry_at timestamp with time zone,
ADD COLUMN IF NOT EXISTS retry_reason text;

-- Create payment retry function
CREATE OR REPLACE FUNCTION public.schedule_payment_retry(
  p_payment_id uuid,
  p_reason text
)
RETURNS timestamp with time zone
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = ''
AS $$
DECLARE
  v_retry_count integer;
  v_next_retry timestamp with time zone;
BEGIN
  -- Get current retry count
  SELECT retry_count INTO v_retry_count
  FROM public.payments
  WHERE id = p_payment_id;

  -- Calculate next retry time (exponential backoff)
  v_next_retry := NOW() + (power(2, v_retry_count) * interval '1 hour');

  -- Update payment record
  UPDATE public.payments
  SET retry_count = retry_count + 1,
      last_retry_at = NOW(),
      next_retry_at = v_next_retry,
      retry_reason = p_reason,
      updated_at = NOW()
  WHERE id = p_payment_id;

  RETURN v_next_retry;
END;
$$;

-- Add index for retry processing
CREATE INDEX idx_payments_retry_queue
ON public.payments(next_retry_at)
WHERE status IN ('failed', 'pending')
AND retry_count < 5;

COMMIT;

-- Rollback Script:
DROP FUNCTION IF EXISTS public.schedule_payment_retry;
DROP INDEX IF EXISTS idx_payments_retry_queue;
ALTER TABLE public.payments
  DROP COLUMN IF EXISTS retry_count,
  DROP COLUMN IF EXISTS last_retry_at,
  DROP COLUMN IF EXISTS next_retry_at,
  DROP COLUMN IF EXISTS retry_reason;
```

### Migration 3.3: Audit Trail Enhancement
```sql
-- Migration: 20250625_audit_trail_enhancement
-- Description: Add comprehensive audit logging
-- Execution Time: < 1 minute
-- Risk: LOW

BEGIN;

-- Create audit log table
CREATE TABLE IF NOT EXISTS public.audit_logs (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  table_name text NOT NULL,
  record_id uuid NOT NULL,
  action text NOT NULL CHECK (action IN ('INSERT', 'UPDATE', 'DELETE')),
  old_data jsonb,
  new_data jsonb,
  changed_fields text[],
  user_id uuid,
  user_email text,
  user_role text,
  ip_address inet,
  user_agent text,
  created_at timestamp with time zone DEFAULT NOW()
);

-- Add indexes
CREATE INDEX idx_audit_logs_record ON public.audit_logs(table_name, record_id);
CREATE INDEX idx_audit_logs_user ON public.audit_logs(user_id);
CREATE INDEX idx_audit_logs_created ON public.audit_logs(created_at DESC);

-- Create generic audit function
CREATE OR REPLACE FUNCTION public.create_audit_log()
RETURNS trigger
LANGUAGE plpgsql
SET search_path = ''
AS $$
DECLARE
  v_old_data jsonb;
  v_new_data jsonb;
  v_changed_fields text[];
  v_user_id uuid;
  v_user_email text;
  v_user_role text;
BEGIN
  -- Get user info
  v_user_id := auth.uid();
  
  IF v_user_id IS NOT NULL THEN
    SELECT email, role INTO v_user_email, v_user_role
    FROM public.profiles
    WHERE id = v_user_id;
  END IF;

  IF TG_OP = 'DELETE' THEN
    v_old_data := to_jsonb(OLD);
    INSERT INTO public.audit_logs (
      table_name, record_id, action, old_data, 
      user_id, user_email, user_role
    ) VALUES (
      TG_TABLE_NAME, OLD.id, TG_OP, v_old_data,
      v_user_id, v_user_email, v_user_role
    );
    RETURN OLD;
  ELSIF TG_OP = 'UPDATE' THEN
    v_old_data := to_jsonb(OLD);
    v_new_data := to_jsonb(NEW);
    
    -- Get changed fields
    SELECT array_agg(key) INTO v_changed_fields
    FROM jsonb_each(v_old_data)
    WHERE value IS DISTINCT FROM v_new_data->key;
    
    INSERT INTO public.audit_logs (
      table_name, record_id, action, old_data, new_data,
      changed_fields, user_id, user_email, user_role
    ) VALUES (
      TG_TABLE_NAME, NEW.id, TG_OP, v_old_data, v_new_data,
      v_changed_fields, v_user_id, v_user_email, v_user_role
    );
    RETURN NEW;
  ELSIF TG_OP = 'INSERT' THEN
    v_new_data := to_jsonb(NEW);
    INSERT INTO public.audit_logs (
      table_name, record_id, action, new_data,
      user_id, user_email, user_role
    ) VALUES (
      TG_TABLE_NAME, NEW.id, TG_OP, v_new_data,
      v_user_id, v_user_email, v_user_role
    );
    RETURN NEW;
  END IF;
END;
$$;

-- Add audit triggers to critical tables
CREATE TRIGGER audit_bookings
AFTER INSERT OR UPDATE OR DELETE ON public.bookings
FOR EACH ROW EXECUTE FUNCTION public.create_audit_log();

CREATE TRIGGER audit_payments
AFTER INSERT OR UPDATE OR DELETE ON public.payments
FOR EACH ROW EXECUTE FUNCTION public.create_audit_log();

CREATE TRIGGER audit_customers
AFTER INSERT OR UPDATE OR DELETE ON public.customers
FOR EACH ROW EXECUTE FUNCTION public.create_audit_log();

-- Enable RLS
ALTER TABLE public.audit_logs ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Admins can view audit logs" ON public.audit_logs
FOR SELECT
USING (
  EXISTS (
    SELECT 1 FROM public.profiles
    WHERE profiles.id = auth.uid()
    AND profiles.role = 'admin'
  )
);

COMMIT;

-- Rollback Script:
DROP TRIGGER IF EXISTS audit_bookings ON public.bookings;
DROP TRIGGER IF EXISTS audit_payments ON public.payments;
DROP TRIGGER IF EXISTS audit_customers ON public.customers;
DROP FUNCTION IF EXISTS public.create_audit_log();
DROP TABLE IF EXISTS public.audit_logs;
```

---

## Testing Requirements

### Phase 1 Testing Checklist
```sql
-- Test 1: Verify all functions have search_path set
SELECT 
  proname AS function_name,
  CASE 
    WHEN prosrc LIKE '%search_path%' THEN '✓ PASS'
    ELSE '✗ FAIL'
  END AS test_result
FROM pg_proc
WHERE pronamespace = (SELECT oid FROM pg_namespace WHERE nspname = 'public')
AND prokind = 'f';

-- Test 2: Verify RLS policies don't use user_metadata
SELECT 
  tablename,
  policyname,
  CASE 
    WHEN definition LIKE '%user_metadata%' THEN '✗ FAIL - Uses user_metadata'
    ELSE '✓ PASS'
  END AS test_result
FROM pg_policies
WHERE schemaname = 'public';

-- Test 3: Verify price validation works
SELECT 
  public.validate_booking_price(
    '123e4567-e89b-12d3-a456-426614174000'::uuid,
    '2025-01-01'::timestamptz,
    '2025-01-07'::timestamptz,
    500.00
  ) AS should_return_true_or_false;

-- Test 4: Verify admin check functions
SELECT public.is_admin_user() AS admin_check;
```

### Phase 2 Testing Checklist
```sql
-- Test 1: Check index usage
EXPLAIN (ANALYZE, BUFFERS) 
SELECT * FROM bookings 
WHERE customer_id = '123e4567-e89b-12d3-a456-426614174000'::uuid
AND start_date >= '2025-01-01';

-- Test 2: Verify car availability performance
EXPLAIN (ANALYZE, BUFFERS)
SELECT * FROM public.get_car_availability_summary(
  '2025-01-01'::date,
  '2025-01-31'::date,
  NULL
);

-- Test 3: Check denormalized data accuracy
SELECT 
  c.id,
  c.booking_count,
  COUNT(b.id) as actual_count,
  c.booking_count = COUNT(b.id) as match
FROM customers c
LEFT JOIN bookings b ON b.customer_id = c.id
  AND b.overall_status != 'cancelled'
GROUP BY c.id, c.booking_count;
```

### Phase 3 Testing Checklist
```sql
-- Test 1: Verify DocuSeal webhook processing
SELECT public.process_docuseal_webhook(
  '123e4567-e89b-12d3-a456-426614174000'::uuid,
  'submission.completed',
  '{"submission_id": "test123"}'::jsonb
);

-- Test 2: Check payment retry scheduling
SELECT public.schedule_payment_retry(
  '123e4567-e89b-12d3-a456-426614174000'::uuid,
  'Insufficient funds'
);

-- Test 3: Verify audit log creation
INSERT INTO bookings (id, customer_id, car_id, start_date, end_date)
VALUES (gen_random_uuid(), gen_random_uuid(), gen_random_uuid(), '2025-01-01', '2025-01-07');

SELECT * FROM audit_logs 
WHERE table_name = 'bookings' 
ORDER BY created_at DESC 
LIMIT 1;
```

---

## Risk Assessment Matrix

| Migration | Risk Level | Impact | Rollback Time | Testing Required |
|-----------|-----------|---------|---------------|------------------|
| Fix search_path | LOW | Security fix | < 1 min | Function execution |
| Fix RLS policies | HIGH | Auth changes | < 2 min | Full auth testing |
| Add indexes | LOW | Performance | < 5 min | Query plans |
| Date type changes | MEDIUM | Data migration | < 2 min | Data integrity |
| Denormalization | LOW | Performance | < 2 min | Data accuracy |
| DocuSeal | LOW | New feature | < 1 min | Integration test |
| Payment retry | LOW | New feature | < 1 min | Payment flow |
| Audit trail | LOW | New feature | < 2 min | Trigger testing |

---

## Execution Timeline

### Week 1 - Critical Phase
- **Day 1 (First 24 hours)**:
  - Execute all Phase 1 security migrations
  - Run security test suite
  - Monitor for authentication issues
  
- **Day 2 (Next 24 hours)**:
  - Complete Phase 1 testing
  - Begin Phase 2 index creation
  - Monitor query performance

### Week 2 - Optimization Phase
- **Days 3-5**:
  - Complete Phase 2 migrations
  - Run performance benchmarks
  - Monitor for degradation
  
- **Days 6-7**:
  - Begin Phase 3 feature migrations
  - Integration testing
  - Prepare for production

### Week 3 - Feature Phase
- **Days 8-10**:
  - Complete Phase 3 migrations
  - Full system testing
  - Documentation updates
  
- **Days 11-14**:
  - Performance monitoring
  - Bug fixes
  - Final optimization

---

## Monitoring Requirements

### Real-time Monitoring
```sql
-- Monitor slow queries
SELECT 
  query,
  calls,
  mean_exec_time,
  total_exec_time
FROM pg_stat_statements
WHERE mean_exec_time > 100
ORDER BY mean_exec_time DESC;

-- Monitor index usage
SELECT 
  schemaname,
  tablename,
  indexname,
  idx_scan,
  idx_tup_read,
  idx_tup_fetch
FROM pg_stat_user_indexes
ORDER BY idx_scan;

-- Monitor table bloat
SELECT 
  schemaname,
  tablename,
  n_dead_tup,
  n_live_tup,
  round(n_dead_tup::numeric / NULLIF(n_live_tup, 0), 2) as dead_ratio
FROM pg_stat_user_tables
WHERE n_live_tup > 0
ORDER BY dead_ratio DESC;
```

### Post-Migration Validation
```sql
-- Validate all functions have search_path
SELECT COUNT(*) = 0 as all_fixed
FROM pg_proc p
JOIN pg_namespace n ON p.pronamespace = n.oid
WHERE n.nspname = 'public'
AND p.prokind = 'f'
AND p.prosrc NOT LIKE '%search_path%';

-- Validate RLS policies
SELECT COUNT(*) = 0 as all_fixed
FROM pg_policies
WHERE schemaname = 'public'
AND definition LIKE '%user_metadata%';

-- Validate indexes exist
SELECT 
  tablename,
  COUNT(*) as index_count
FROM pg_indexes
WHERE schemaname = 'public'
GROUP BY tablename
ORDER BY index_count;
```

---

## Rollback Procedures

Each migration includes specific rollback scripts. General rollback procedure:

1. **Immediate Rollback** (< 5 minutes):
   ```sql
   -- Connect to database
   -- Run specific rollback script for failed migration
   -- Verify system stability
   ```

2. **Checkpoint Rollback** (< 30 minutes):
   ```sql
   -- Restore from last checkpoint
   -- Re-run successful migrations only
   -- Skip failed migration
   ```

3. **Full Rollback** (< 2 hours):
   ```sql
   -- Restore from pre-migration backup
   -- Investigate failure cause
   -- Revise migration plan
   ```

---

## Success Criteria

### Phase 1 Success
- [ ] All 27 functions have SET search_path
- [ ] No RLS policies reference user_metadata
- [ ] Price validation functions operational
- [ ] Admin authentication working correctly

### Phase 2 Success
- [ ] Query performance improved by >50%
- [ ] No N+1 query patterns detected
- [ ] All date fields using proper types
- [ ] Index hit ratio >95%

### Phase 3 Success
- [ ] DocuSeal webhooks processing
- [ ] Payment retry logic active
- [ ] Audit trail capturing all changes
- [ ] All integration tests passing

---

## Conclusion

This migration plan addresses all critical issues identified by previous agents. Phase 1 MUST be executed within 48 hours to resolve security vulnerabilities blocking deployment. Phases 2 and 3 can be executed based on business priorities but are recommended within the timeline specified.

**Next Steps:**
1. Review this plan with the team
2. Set up migration environment
3. Create database backups
4. Begin Phase 1 execution
5. Monitor and validate each migration

**Contact for Issues:**
- Database Team Lead
- Security Team (for Phase 1)
- DevOps (for execution support)